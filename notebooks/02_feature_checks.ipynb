{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# 1) Imports & feature view\n",
    "import os, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(); engine = create_engine(os.getenv(\"POSTGRES_URL\"))\n",
    "\n",
    "SQL = \"\"\"\n",
    "select ra.season, ra.round, r.race_id, r.driver_id,\n",
    "       r.grid, df.form_points_5, tp.team_quali_pos5, q.position as quali_pos,\n",
    "       (r.grid - q.position) as grid_vs_quali, coalesce(w.is_wet,false) as is_wet,\n",
    "       (r.position between 1 and 10) as is_top10\n",
    "from raw.results r\n",
    "join raw.races ra using (race_id)\n",
    "left join staging.driver_form df using (race_id, driver_id)\n",
    "left join staging.team_pace tp using (race_id)\n",
    "left join raw.qualifying q using (race_id, driver_id)\n",
    "left join raw.weather w using (race_id)\n",
    "where r.position is not null\n",
    "\"\"\"\n",
    "df = pd.read_sql(text(SQL), engine)\n",
    "features = [\"grid\",\"form_points_5\",\"team_quali_pos5\",\"quali_pos\",\"grid_vs_quali\",\"is_wet\"]\n",
    "X = df[features].fillna(0)\n",
    "y = df[\"is_top10\"].astype(int)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 2) GroupKFold by season (time‑aware)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "preds, trues = [], []\n",
    "for tr, va in cv.split(X, y, groups=df[\"season\"]):\n",
    "    model = XGBClassifier(n_estimators=400, max_depth=5, learning_rate=0.05, subsample=0.8, colsample_bytree=0.9, reg_lambda=2.0)\n",
    "    model.fit(X.iloc[tr], y.iloc[tr])\n",
    "    p = model.predict_proba(X.iloc[va])[:,1]\n",
    "    preds.extend(p); trues.extend(y.iloc[va].tolist())\n",
    "auc = roc_auc_score(trues, preds); brier = brier_score_loss(trues, preds)\n",
    "print({\"cv_auc\": round(auc,4), \"cv_brier\": round(brier,4)})"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 3) Reliability (calibration) curve\n",
    "bins = np.linspace(0,1,11)\n",
    "inds = np.digitize(preds, bins)-1\n",
    "df_cal = pd.DataFrame({\"bin\": inds, \"pred\": preds, \"y\": trues}).groupby(\"bin\").agg(pred_mean=(\"pred\",\"mean\"), actual_rate=(\"y\",\"mean\"))\n",
    "ax = df_cal.plot(y=[\"pred_mean\",\"actual_rate\"], marker='o'); ax.set_title(\"Calibration: predicted vs actual\");"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4) Feature importance (gain)\n",
    "model = XGBClassifier(n_estimators=400, max_depth=5, learning_rate=0.05)\n",
    "model.fit(X, y)\n",
    "imp = pd.Series(model.get_booster().get_score(importance_type='gain'))\n",
    "imp.sort_values(ascending=False).plot(kind='bar', figsize=(8,3));"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 5) Add a new feature experiment: driver consistency (finish pos std over last 5)\n",
    "SQL_new = \"\"\"\n",
    "with res as (\n",
    "  select driver_id, race_id, season, round, position,\n",
    "         row_number() over (partition by driver_id order by season, round) as rn\n",
    "  from raw.results r join raw.races ra using (race_id)\n",
    ")\n",
    "select r1.driver_id, r1.race_id, stddev_pop(r2.position) as driver_consistency5\n",
    "from res r1 join res r2 on r1.driver_id=r2.driver_id and r2.rn between r1.rn-5 and r1.rn-1\n",
    "group by 1,2\n",
    "\"\"\"\n",
    "cons = pd.read_sql(text(SQL_new), engine)\n",
    "base = pd.read_sql(text(SQL), engine)\n",
    "X2 = (base.merge(cons, on=[\"race_id\",\"driver_id\"], how=\"left\")\n",
    "          .assign(driver_consistency5=lambda d: d.driver_consistency5.fillna(d.driver_consistency5.median()))\n",
    "          [features + [\"driver_consistency5\"]])"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 6) Re‑evaluate with the new feature\n",
    "cv = GroupKFold(n_splits=5)\n",
    "preds, trues = [], []\n",
    "for tr, va in cv.split(X2, y, groups=base[\"season\"]):\n",
    "    model = XGBClassifier(n_estimators=400, max_depth=5, learning_rate=0.05)\n",
    "    model.fit(X2.iloc[tr], y.iloc[tr])\n",
    "    p = model.predict_proba(X2.iloc[va])[:,1]\n",
    "    preds.extend(p); trues.extend(y.iloc[va].tolist())"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 7) Log the experiment\n",
    "from datetime import datetime\n",
    "log = {\n",
    "    \"ts\": datetime.utcnow().isoformat(),\n",
    "    \"added_features\": [\"driver_consistency5\"],\n",
    "    \"cv_auc\": float(roc_auc_score(trues, preds)),\n",
    "    \"notes\": \"Stddev of recent finishes captures volatility; keep if > +0.003 AUC\"\n",
    "}\n",
    "log"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 8) Save figures for BI/README\n",
    "out = \"../bi/screenshots\"; os.makedirs(out, exist_ok=True)\n",
    "ax.figure.savefig(f\"{out}/calibration_curve.png\", bbox_inches='tight')\n",
    "print(\"AUC with new feature:\", roc_auc_score(trues, preds))"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}